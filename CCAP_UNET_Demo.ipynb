{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aml7hawaiiedu/CCAPLandCoverProject/blob/main/CCAP_UNET_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6-_rOVHH3if"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This is Amanda's version of UNET_regression_demo_whp (Aron's original code)\n",
        "  \n",
        "This is an Earth Engine <> TenserFlow demonstration notebook. Suppose you want to predict a continuous output (regression) from a stack of continuous inputs. In this example, the output is impervious surface area from [NLCD](https://www.mrlc.gov/data) and the input is a Landsat 8 composite. The model is a [fully convolutional neural network  (FCNN)](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf), specifically [U-net](https://arxiv.org/abs/1505.04597). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okAzQzK0J4HS"
      },
      "outputs": [],
      "source": [
        "# Google Cloud Platform authentication.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXQd9K91KLIx",
        "outputId": "c5e652a0-9bd4-4310-8a46-2de01df87793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=RiJovszKh1ou51nDhHloERsPyYwvafe0yvSqA4DnEEU&tc=-E6Fp0d_XCw0cRCo4yUHyg1rgnM7n0kZf0SY91vmEo4&cc=qbXrOcn2gEy6UDez8JXI3X32g4vBkBEo7AyGw0d2duY\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n",
            "Enter verification code: 4/1AVHEtk7YtqObgLMU1gfIDvaUq4YJdH2iuOFWk5dbj1epK8fv2irbgozZI3c\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ],
      "source": [
        "# Import Google Earth Engine Python API, authenticate user's credentials, and initialize the Earth Engine library.\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N6SCzKDKc5g",
        "outputId": "3366c27a-852f-42a3-a2be-71826b2f228a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "# Tensorflow is an open-source machine learning library developed by Google. It is wildly used for building deep learning models.\n",
        "# Print the version.\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3qKGJ7evWG7",
        "outputId": "cdd2f1ba-135d-4fb3-b36e-b26d06580999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.14.0\n"
          ]
        }
      ],
      "source": [
        "# Folium is a Python library used for creating interactive maps and visualizations.\n",
        "# Print the version. \n",
        "import folium\n",
        "print(folium.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGuJGj71zX2a"
      },
      "outputs": [],
      "source": [
        "# Name of the Google Cloud Storage (GCS) bucket where data will be stored or accessed from.\n",
        "# GCS is cloud-based object storage service used to store and access large amounts of data in a highly scalable and durable manner. \n",
        "# It is common to define a bucket which serves as a top-level container. \n",
        "BUCKET = 'remote_sensing_fuckit_bucket'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWSU2lVyzYVI"
      },
      "outputs": [],
      "source": [
        "# Name of the folder that will be used to store data related to the wetland U-Net model.\n",
        "# Name of the subfolder within 'FOLDER' directory that will be used to store training patches or data used to train the wetland classification model. \n",
        "# Name of the subfolder within 'FOLDER' directory that will be used to store evaluation patches or data used to test the wetland classification model. \n",
        "FOLDER = 'wetland_unet'\n",
        "TRAINING_BASE = 'training_patches'\n",
        "EVAL_BASE = 'eval_patches'\n",
        "\n",
        "# These lines of code specify the input features for the wetland U-Net model and the response variable that the model will be trained to predict.\n",
        "# opticalBands is assigned as a list of string values, which correspond to the names of the optical bands that are present in the Landsat satellite imagery.\n",
        "# thermalBands is assigned a list of string values, which correspond to the names of the optical bands that are present in the Landsat satellite imagery.\n",
        "# BANDS is assigned the concatenation of the 'opticalBands' and 'thermalBands'. This represents a list of all the bands that will be used as features in the U-Net model.\n",
        "# RESPONSE is assigned the string value 'b1' which corresponds to the name of the response variable that the U-Net model will be trained to predict. \n",
        "# FEATURES is assigned the concatenation of the 'BANDS' list and the 'RESPONSE' variables. This represents a list of all the features that will be used to train the U-Net model. \n",
        "opticalBands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
        "thermalBands = ['B10', 'B11']\n",
        "BANDS = opticalBands + thermalBands\n",
        "RESPONSE = 'b1'\n",
        "FEATURES = BANDS + [RESPONSE]\n",
        "\n",
        "# Specify the inputs\n",
        "# These lines of code specify the size and shape of patches that the U-Net model expects as input, as well as a dictionary that maps featue names to columns in an TenserFlow dataset. \n",
        "# KERNEL_SIZE is assigned the integer value '128' which represents the size of patches that the U-Net model expects as input.\n",
        "# KERNEL_SHAPE is assigned a list contning two elements, both of which are equal to 'KERNEL_SIZE'. This represents the shape of the patches the U-Net model expects as an input.\n",
        "# COLUMNS is assigned a list of TenserFlow 'fixedLenFeature' objects, which specify the expected shape and data type of each feature column in a Tenserflow dataset. \n",
        "  # 'shape' is set to 'KERNEL_SHAPE' and 'dtype' is set to 'tf.float32'. The list comprehension used here creates one 'fixedLenFeature' object for each feature in the 'FEATURES' list/ \n",
        "# FEATURE_DICT is assigned a Python dictionary that maps feature names to their corresponding columns in a TenserFlow dataset. \n",
        "  # 'zip' is used to create tuples parining each feature name from the 'FEATURES' list with its corresponding 'fixedLenFeature' object from the 'COLUMNS' list. \n",
        "  # The 'dict' function is then used to convert this list of tuples into a dictionary. \n",
        "KERNEL_SIZE = 128\n",
        "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
        "COLUMNS = [\n",
        "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
        "]\n",
        "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
        "\n",
        "# Define the size of the training and evaluation datasets that will be used to train and evaluate the U-Net model. \n",
        "# TRAIN_SIZE is assigned the integer value '1600' which represents the size of the training dataset.\n",
        "# EVAL_SIZE is assigned the integer value '800' which represents the size of the evaluation dataset. \n",
        "TRAIN_SIZE = 1600\n",
        "EVAL_SIZE = 800\n",
        "\n",
        "# Specify model training parameters.\n",
        "# Define model training parameters that will be used to train and evaluate the U-Net model. \n",
        "# BATCH_SIZE represents the number of training examples that will be used in each training iteration. \n",
        "# EPOCHS represents the number of times that each training dataset will be used to train the model. \n",
        "# BUFFER_SIZE represents the number of elements from the training dataset that will be pre-fetched and buffered in order to optimize data reading during training. \n",
        "# OPTIMIZER specifies the Stochastic Gradient Descent optimization algorithm will be used during training. \n",
        "  # ? what other optimizers would work? Is this the best one for this type of model?\n",
        "# LOSS specifies the Mean Squared Error Loss function will be used during training. \n",
        "# METRICS is asigned a list containing the sting value 'RootMeanSquareError' which specifies RMSE metric will be used to evaluate the performance of the model during training. \n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "BUFFER_SIZE = 2000\n",
        "OPTIMIZER = 'SGD'\n",
        "LOSS = 'MeanSquaredError'\n",
        "METRICS = ['RootMeanSquaredError']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "tnLLLqcmzeVR",
        "outputId": "c53b4514-d8a5-4e8f-c343-a122ccfab751"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_da71da9efeb9a78b5b2e1a804ef5b260 {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_da71da9efeb9a78b5b2e1a804ef5b260&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_da71da9efeb9a78b5b2e1a804ef5b260 = L.map(\n",
              "                &quot;map_da71da9efeb9a78b5b2e1a804ef5b260&quot;,\n",
              "                {\n",
              "                    center: [21.4, -158.0],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 10,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_7363d937ab1d61237aa7eb4c7ead2980 = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_da71da9efeb9a78b5b2e1a804ef5b260);\n",
              "        \n",
              "    \n",
              "            var tile_layer_0bb0fdbb64cf17c0da4ba9840c1b7497 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/db2bb984dd835d42ff4c3341ecbc8ac4-4c5267b67874cc62c9824ce885e60698/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_da71da9efeb9a78b5b2e1a804ef5b260);\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x7f4b18a73a90>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use Landsat 8 surface reflectance data.\n",
        "# Use EE Python API to initialize an image collection. \n",
        "# Specify Landsat 8 surface reflectance image collection. \n",
        "# l8sr is the name of the object to be used in subsequent operations.\n",
        "l8sr = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
        "\n",
        "# This code defines a function 'maskL8sr' that will be used to apply cloud masking to Landsat 8 surface reflectance images.\n",
        "def maskL8sr(image):\n",
        "  cloudShadowBitMask = ee.Number(2).pow(3).int()\n",
        "  cloudsBitMask = ee.Number(2).pow(5).int()\n",
        "  qa = image.select('pixel_qa')\n",
        "  mask1 = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(\n",
        "    qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
        "  mask2 = image.mask().reduce('min')\n",
        "  mask3 = image.select(opticalBands).gt(0).And(\n",
        "          image.select(opticalBands).lt(10000)).reduce('min')\n",
        "  mask = mask1.And(mask2).And(mask3)\n",
        "  return image.select(opticalBands).divide(10000).addBands(\n",
        "          image.select(thermalBands).divide(10).clamp(273.15, 373.15)\n",
        "            .subtract(273.15).divide(100)).updateMask(mask)\n",
        "\n",
        "\n",
        "\n",
        "# The image input data is a cloud-masked median composite.\n",
        "# Filter the l8sr image collection by date, selecting only images from the date range identified. \n",
        "# Apply the mask function to each image in the resulting collection using the map() method. \n",
        "  # This function applies a mask to each image and rescales the reflectance and temperature bands to a 0-1 range. \n",
        "# Calculate the median value of the resulting image collection using the median() method.\n",
        "# Assign the variable name; in this case 'ls_2017'. \n",
        "# The resulting 'ls_2017' image will be used for training and evaluation of our U-Net model. \n",
        "ls_2017 = l8sr.filterDate('2017-05-01', '2017-09-30').map(maskL8sr).median()\n",
        "\n",
        "\n",
        "# Create single mosaic\n",
        "#ls_3yr_mosaic =  ls_2017.addBands(ls_2018)\n",
        "#ls_3yr_mosaic = ls_3yr_mosaic.addBands(ls_2019)\n",
        "\n",
        "#Reset band names to new stack\n",
        "#BANDS = ls_3yr_mosaic.bandNames().getInfo()\n",
        "#FEATURES = BANDS + [RESPONSE]\n",
        "\n",
        "# Use folium to visualize the imagery.\n",
        "# map = folium.Map(location=[21.4, -158.])\n",
        "\n",
        "\n",
        "\n",
        "# Use 'getMapID()' method to get a map ID for the 'ls_2017' image. \n",
        "# Specify that we want to visualize band 2 of the image using 'bands':['B2']. Set the min and max.\n",
        "# Create a folium map object centered at specific location using 'folium.Map()'. \n",
        "# Add a tile layer to the map using 'folium.TileLayer()' method, specifying the URL format of the tiles using the 'tiles' argument and adding 'attr' attribution info. \n",
        "# Set the overlay flag to 'True' and provide a name for the layer using 'name'. \n",
        "# Finally, add the tile layer to the map using '.add_to()' method. \n",
        "  # This allows us to visualize the 'ls_2017' image in the folium map. \n",
        "mapid_17 =ls_2017.getMapId({'bands': ['B2'], 'min': 0, 'max': 0.3})\n",
        "map = folium.Map(location=[21.4, -158.])\n",
        "folium.TileLayer(\n",
        "    tiles=mapid_17['tile_fetcher'].url_format,\n",
        "    attr = 'Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name = '17 median composite',\n",
        "    ).add_to(map)\n",
        "\n",
        "map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Slxl78VA2J8A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4X7EyYwv6m0"
      },
      "outputs": [],
      "source": [
        "# One Hot Encoding function.\n",
        "# 'oneHot()' function is used for One Hot Encoding of an image. \n",
        "  # Each pixel in the image is replaced by a binary vector of length 'n' where 'n' is the number of classes in the image. \n",
        "# image : image to be encoded\n",
        "# code : the class code that will be encoded as '1' in the output, while all other classes are encoded as '0'\n",
        "# The function compares each pixel value in the input 'image' with the 'code' value using the 'ee.image.eq()' finction. \n",
        "# The 'ee.image.eq()' function returns a binary image with the same dimensions as the input image, where each pixel is '1' if the input pixel is equal to the given 'code' value and '0' otherwise. \n",
        "# The resulting binary image is returned as the 'one_hot_image' encoded. \n",
        "def oneHot(image,code = 1):\n",
        "  one_hot_image = image.eq(code)\n",
        "  return one_hot_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "KxvKSAGh_7D3",
        "outputId": "89564c50-7b84-471d-cbca-828ea780f37e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_c8236ab10bf84884da4902673bd5ce73 {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_c8236ab10bf84884da4902673bd5ce73&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_c8236ab10bf84884da4902673bd5ce73 = L.map(\n",
              "                &quot;map_c8236ab10bf84884da4902673bd5ce73&quot;,\n",
              "                {\n",
              "                    center: [21.4, -158.0],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 10,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_60c680bcf40b35b98ff0fb43b3a8b3a7 = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_c8236ab10bf84884da4902673bd5ce73);\n",
              "        \n",
              "    \n",
              "            var tile_layer_41ed0e177627c9fa47c5ac6f5c01ebf1 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/6f6172a7708cb45bbd815428fd6e8ce5-92f6918ce374b6fd6657db5411ab5912/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_c8236ab10bf84884da4902673bd5ce73);\n",
              "        \n",
              "    \n",
              "            var layer_control_97171079d8ba42633281ba79767583fb = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_60c680bcf40b35b98ff0fb43b3a8b3a7,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;NOAA CCAP Land Cover&quot; : tile_layer_41ed0e177627c9fa47c5ac6f5c01ebf1,\n",
              "                },\n",
              "            };\n",
              "            L.control.layers(\n",
              "                layer_control_97171079d8ba42633281ba79767583fb.base_layers,\n",
              "                layer_control_97171079d8ba42633281ba79767583fb.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_c8236ab10bf84884da4902673bd5ce73);\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x7f4b12e2b310>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get imagecollection from google earth engine - NOAA C-CAP land cover data for Hawaii \n",
        "# This code gets an EE image collection which contains the land cover data for Hawaii form the NOAA Coastal Change Analysis Program (C-CAP)\n",
        "wetland = ee.ImageCollection(\"projects/sat-io/open-datasets/HRLC/CCAP_HI_LC\")\n",
        "\n",
        "# Filter image collection to include images within a specified date range. \n",
        "# The 'mosaic()' function is used to combine all the images in the filtered collection into a single image, which represents the most recent pixel value at each location. \n",
        "# This is done to reduce the numer of images in the collection and to create a single image for analysis. \n",
        "wetland = wetland.filterDate('2010-01-01', '2022-01-01').mosaic()\n",
        "\n",
        "# Mask out pixels with a value of 0 in the 'wetland' image using the mask() function.\n",
        "# This ensures the modeld doesn't predict or train on data outside of the acutual land cover area. \n",
        "wetland = wetland.mask(wetland.gt(0))\n",
        "\n",
        "# This generates a one-hot encoding representation of the land cover classification image for Hawaii obtained from the NOAA C-CAP dataset.\n",
        "# For each of the 25 land cover classes present in the image, the code creates a binary image where pixels with the corresponding class are set to 1 and pixels with other classes are set to 0.\n",
        "# The reutning binary iamges are stored in a list 'wetland_oneHot'.\n",
        "# The list is converted to a single multi-band image.\n",
        "# The bands of the multi-image are renamed to correspond to the class lables.\n",
        "wetland_oneHot = []\n",
        "for code in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]:\n",
        "  one_hot_image = oneHot(wetland,code)\n",
        "  wetland_oneHot.append(one_hot_image)\n",
        "wetland_oneHot = ee.Image(wetland_oneHot)\n",
        "wetland_oneHot = wetland_oneHot.rename(['p1','p2','p3','p4','p5','p6','p7','p8','p9','p10','p11','p12','p13','p14','p15','p16','p17','p18','p19','p20','p21','p22','p23','p24','p25'])\n",
        "\n",
        "# Use folium to visualize the imagery.\n",
        "# The 'wetland_oneHot' image is used to generate the map ID. \n",
        "# The min and max are set to 0 and 1 to display the binary values of the one-hot encoding. \n",
        "mapid = wetland_oneHot.getMapId({'bands': ['p15','p10','p2'],'min': 0, 'max': 1})\n",
        "map = folium.Map(location=[21.4, -158])\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='NOAA CCAP Land Cover',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEk2QDx1_66B"
      },
      "source": [
        "Stack the 2D images (Landsat  and NOAA C-CAP land cover data for Hawaii) to create a single image from which samples can be taken. \n",
        "\n",
        "Convert the image into an array image in which each pixel stores 128x128 patches of pixels for each band. \n",
        "\n",
        "This is a key step that bears emphasis: to export training patches, convert a multi-band image to an array image using neighborhoodToArray(), then sample the image at points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozHkvbb76hv9",
        "outputId": "88f73ad1-3ac1-4b86-b3ff-3b22de7126de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25']\n",
            "['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'B11']\n"
          ]
        }
      ],
      "source": [
        "# There are 25 strings in the list. \n",
        "RESPONSE = ['p1','p2','p3','p4','p5','p6','p7','p8','p9','p10','p11','p12','p13','p14','p15','p16','p17','p18','p19','p20','p21','p22','p23','p24','p25']\n",
        "print(RESPONSE)\n",
        "print(BANDS)\n",
        "\n",
        "\n",
        "# Create a feature stack by concatenating two image collections and converting the result to float.\n",
        "featureStack = ee.Image.cat([\n",
        "  ls_2017.select(BANDS),\n",
        "  wetland_oneHot.select(RESPONSE)\n",
        "]).float()\n",
        "\n",
        "# Define a kernel that will be used for image processing operations. \n",
        "# The kernel is initialized with a list of ones, meaning that each pixel in the kernel will have a weight of one when applied to the image. \n",
        "list = ee.List.repeat(1, KERNEL_SIZE)\n",
        "lists = ee.List.repeat(list, KERNEL_SIZE)\n",
        "kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
        "\n",
        "# Convert the neighborhood values within the kernel to arrays.\n",
        "# Create a new array image where each pixel value is an array representing the neighborhood of the corresponding pixel in the original feature stack. \n",
        "# THe size of the neighborhood is dertermined by the size of the kernel. \n",
        "# 'neighborhoodToArray' is an EE function that converst an image to an array image. \n",
        "arrays = featureStack.neighborhoodToArray(kernel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLV1CArWZWEe",
        "outputId": "f50e928f-b4aa-4396-c5aa-a4e3549d462d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'B1': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'B2': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'B3': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'B4': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'B5': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'B6': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'B7': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'B10': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'B11': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p1': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p2': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p3': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p4': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p5': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p6': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p7': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p8': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p9': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p10': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p11': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p12': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p13': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p14': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p15': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p16': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p17': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p18': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p19': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p20': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p21': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p22': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p23': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p24': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'p25': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None)}\n"
          ]
        }
      ],
      "source": [
        "# RESPONSE = 'b1'\n",
        "\n",
        "FEATURES = BANDS + RESPONSE\n",
        "\n",
        "\n",
        "# Specify the size and shape of patches expected by the model.\n",
        "# KERNEL_SIZE = KERNEL_SIZE\n",
        "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
        "COLUMNS = [\n",
        "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
        "]\n",
        "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
        "\n",
        "print(FEATURES_DICT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD5sj0X-aIXP",
        "outputId": "be6bbc16-6b45-4488-d5ad-51ea774b049d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'B11', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25']\n"
          ]
        }
      ],
      "source": [
        "print(featureStack.bandNames().getInfo())\n",
        "# print(arrays)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zYcnA30aPEj"
      },
      "source": [
        "Use some pre-made geometries to sample the stack in strategic locations. \n",
        "\n",
        "Specifically, these are hand-made polygons in which to take the 128x128 samples. \n",
        "\n",
        "Display the sampling polygons on a map, red for training polygons, blue for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "dM41nHujaMvY",
        "outputId": "f6373ac0-5e4a-41fc-93cb-299070f14e40"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_56223ae57baa45e0b139fc11d49cd64a {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_56223ae57baa45e0b139fc11d49cd64a&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_56223ae57baa45e0b139fc11d49cd64a = L.map(\n",
              "                &quot;map_56223ae57baa45e0b139fc11d49cd64a&quot;,\n",
              "                {\n",
              "                    center: [21.4, -158.0],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 4,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_7aa8fceebc8c65463e1108eb51cee7a0 = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_56223ae57baa45e0b139fc11d49cd64a);\n",
              "        \n",
              "    \n",
              "            var tile_layer_335d672ec273065c1d3bb8044edf6782 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/ae4f15df765f7d2d0757de418cd8d10b-8dc58a400dbb920ae0531f862f76cf6f/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_56223ae57baa45e0b139fc11d49cd64a);\n",
              "        \n",
              "    \n",
              "            var layer_control_77de3f51e99fb1cabb6908a9c8a22e50 = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_7aa8fceebc8c65463e1108eb51cee7a0,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;training polygons&quot; : tile_layer_335d672ec273065c1d3bb8044edf6782,\n",
              "                },\n",
              "            };\n",
              "            L.control.layers(\n",
              "                layer_control_77de3f51e99fb1cabb6908a9c8a22e50.base_layers,\n",
              "                layer_control_77de3f51e99fb1cabb6908a9c8a22e50.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_56223ae57baa45e0b139fc11d49cd64a);\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x7f4b18a3b9d0>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# FeatureCollection is a colelction of featuers, where each feature is represented as a dictionary of properties and a geometry that describes its spatial extent. \n",
        "# The trainingPolys features in this are used to train the model to recognize land cover types based on the spectral and spatial features extracted from satellite imagery. \n",
        "# The evalPolys features are used to evaluate the accuracy of the trained model. \n",
        "trainingPolys = ee.FeatureCollection('projects/ee-seismosmsr-landcover/assets/trainingPolys_ccap')\n",
        "evalPolys = ee.FeatureCollection('projects/ee-seismosmsr-landcover/assets/evalPolys')\n",
        "\n",
        "# Create an empty image.\n",
        "# Create a labled image where the pixles belonging to the training set have a value of 1 and evaluation set have a value of 2.\n",
        "polyImage = ee.Image(0).byte().paint(trainingPolys, 1).paint(evalPolys, 2)\n",
        "polyImage = polyImage.updateMask(polyImage)\n",
        "\n",
        "\n",
        "# Use folium to visualize EE image. \n",
        "mapid = polyImage.getMapId({'min': 1, 'max': 2, 'palette': ['red', 'blue']})\n",
        "map = folium.Map(location=[21.4, -158.], zoom_start=4)\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='training polygons',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpQSamAvhZMx",
        "outputId": "ce4faf41-ffe3-41d0-ec5e-5dab90375e9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'B11', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25']\n"
          ]
        }
      ],
      "source": [
        "# Convert the feature collections to lists for iteration.\n",
        "trainingPolysList = trainingPolys.toList(trainingPolys.size())\n",
        "evalPolysList = evalPolys.toList(evalPolys.size())\n",
        "\n",
        "# These numbers determined experimentally.\n",
        "n = 5 # Number of shards in each polygon.\n",
        "N = 200 # Total sample size in each polygon.\n",
        "\n",
        "# Export all the training data (in many pieces), with one task \n",
        "# per geometry.\n",
        "print(BANDS+RESPONSE)\n",
        "# print()\n",
        "for g in range(trainingPolys.size().getInfo()):\n",
        "  geomSample = ee.FeatureCollection([])\n",
        "  for i in range(n):\n",
        "    sample = arrays.sample(\n",
        "      region = ee.Feature(trainingPolysList.get(g)).geometry(), \n",
        "      scale = 30,\n",
        "      numPixels = N / n, # Size of the shard.\n",
        "      seed = i,\n",
        "      tileScale = 8\n",
        "    )\n",
        "    geomSample = geomSample.merge(sample)\n",
        "    \n",
        "  desc = TRAINING_BASE + '_g' + str(g)\n",
        "  task = ee.batch.Export.table.toCloudStorage(\n",
        "    collection = geomSample,\n",
        "    description = desc,\n",
        "    bucket = BUCKET,\n",
        "    fileNamePrefix = FOLDER + '/' + desc,\n",
        "    fileFormat = 'TFRecord'\n",
        "    # selectors = BANDS + RESPONSE\n",
        "  )\n",
        "  task.start()\n",
        "\n",
        "# Export all the evaluation data.\n",
        "for g in range(evalPolys.size().getInfo()):\n",
        "  geomSample = ee.FeatureCollection([])\n",
        "  for i in range(n):\n",
        "    sample = arrays.sample(\n",
        "      region = ee.Feature(evalPolysList.get(g)).geometry(), \n",
        "      scale = 30,\n",
        "      numPixels = N / n,\n",
        "      seed = i,\n",
        "      tileScale = 8\n",
        "    )\n",
        "    geomSample = geomSample.merge(sample)\n",
        "\n",
        "  desc = EVAL_BASE + '_g' + str(g)\n",
        "  task = ee.batch.Export.table.toCloudStorage(\n",
        "    collection = geomSample,\n",
        "    description = desc,\n",
        "    bucket = BUCKET,\n",
        "    fileNamePrefix = FOLDER + '/' + desc,\n",
        "    fileFormat = 'TFRecord'\n",
        "    # selectors = BANDS + RESPONSE\n",
        "  )\n",
        "  task.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2WrHB9U5DRT"
      },
      "outputs": [],
      "source": [
        "\n",
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "  Returns:\n",
        "    A dictionary of tensors, keyed by feature name.\n",
        "  \"\"\"\n",
        "  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
        "\n",
        "\n",
        "def to_tuple(inputs):\n",
        "  \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
        "  Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
        "  Args:\n",
        "    inputs: A dictionary of tensors, keyed by feature name.\n",
        "  Returns:\n",
        "    A tuple of (inputs, outputs).\n",
        "  \"\"\"\n",
        "  inputsList = [inputs.get(key) for key in FEATURES]\n",
        "  stacked = tf.stack(inputsList, axis=0)\n",
        "  # Convert from CHW to HWC\n",
        "  stacked = tf.transpose(stacked, [1, 2, 0])\n",
        "  return stacked[:,:,:len(BANDS)], stacked[:,:,len(BANDS):]\n",
        "\n",
        "\n",
        "def get_dataset(pattern):\n",
        "  \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
        "  Get all the files matching the pattern, parse and convert to tuple.\n",
        "  Args:\n",
        "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
        "  Returns:\n",
        "    A tf.data.Dataset\n",
        "  \"\"\"\n",
        "  glob = tf.io.gfile.glob(pattern)\n",
        "  dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
        "  dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "  dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYE9NP8j5OWN"
      },
      "outputs": [],
      "source": [
        "# Define a function that returns a preprocessed dataset for ML. \n",
        "# Match the training data files in GCS bucket.\n",
        "# Calls 'get_dataset' function to read, parse, and convert the input files to tuples of tensors. \n",
        "# The resulting dataset is shuffled, batched, and repeated (epochs) to prepare for ML training. \n",
        "# Save the resulting dataset to 'training' variable. \n",
        "def get_training_dataset():\n",
        "\t\"\"\"Get the preprocessed training dataset\n",
        "  Returns: \n",
        "    A tf.data.Dataset of training data.\n",
        "  \"\"\"\n",
        "\tglob = 'gs://' + BUCKET + '/' + FOLDER + '/' + TRAINING_BASE + '*'\n",
        "\t# print(glob)\n",
        "\tdataset = get_dataset(glob)\n",
        "\tdataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\treturn dataset\n",
        "\n",
        "training = get_training_dataset()\n",
        "\n",
        "# print(iter(training.take(2)).next())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNNJCqsJ5RBx",
        "outputId": "da2452ec-dc65-4af1-9470-204466a08712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gs://remote_sensing_fuckit_bucket/wetland_unet/eval_patches*\n"
          ]
        }
      ],
      "source": [
        "# Return a Tenserflow dataset contaiing the preprocessed evaluation data. \n",
        "# File path to the evaluation data stored in GCS bucket.\n",
        "# Calls 'get_dataset' function to create a TenserFlow dataset containing the evaluation data. \n",
        "# Evaluation dataset is batched with a batchsize of 1, meaning each element of the dataset consists of a single example. \n",
        "# The function returns the resulting evaluation dataset.\n",
        "def get_eval_dataset():\n",
        "\t\"\"\"Get the preprocessed evaluation dataset\n",
        "  Returns: \n",
        "    A tf.data.Dataset of evaluation data.\n",
        "  \"\"\"\n",
        "\tglob = 'gs://' + BUCKET + '/' + FOLDER + '/' + EVAL_BASE + '*'\n",
        "\tprint(glob)\n",
        "\tdataset = get_dataset(glob)\n",
        "\tdataset = dataset.batch(1).repeat()\n",
        "\treturn dataset\n",
        "\n",
        "evaluation = get_eval_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjIctHU75YAB",
        "outputId": "2572ee29-23d7-43b6-bc42-aebb74891ab2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<RepeatDataset element_spec=(TensorSpec(shape=(None, 128, 128, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 128, 128, 25), dtype=tf.float32, name=None))>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nndrupcf5vFi",
        "outputId": "fad89cbf-1dac-4a38-ed22-2ecf5bf767a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS6Culd77wxI"
      },
      "source": [
        "this is the section I need to make modifications to. this is set up for regression, not classification. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPe--dX05zZX"
      },
      "outputs": [],
      "source": [
        "# import TenserFlow classes and functions \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "# from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "# from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "\n",
        "# from tensorflow.keras.layers import BatchNormalization\n",
        "# from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "# from tensorflow.python.keras.layers import BatchNormalization \n",
        "\n",
        "# U-Net model for image segmentation. \n",
        "# Encoder and decoder conncted by a center block. \n",
        "# Encoder downsamples the input image while capturing its features. \n",
        "# Decoder upsamples the encoded image to generate a segmentation map.\n",
        "def conv_block(input_tensor, num_filters):\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('relu')(encoder)\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('relu')(encoder)\n",
        "\treturn encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "\tencoder = conv_block(input_tensor, num_filters)\n",
        "\tencoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "\treturn encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "\tdecoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "\tdecoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('relu')(decoder)\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('relu')(decoder)\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('relu')(decoder)\n",
        "\treturn decoder\n",
        "\n",
        "def get_model():\n",
        "\tinputs = layers.Input(shape=[KERNEL_SIZE, KERNEL_SIZE, len(BANDS)]) # 256\n",
        "\tencoder0_pool, encoder0 = encoder_block(inputs, 32) # 128\n",
        "\tencoder1_pool, encoder1 = encoder_block(encoder0_pool, 64) # 64\n",
        "\tencoder2_pool, encoder2 = encoder_block(encoder1_pool, 128) # 32\n",
        "\tencoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
        "\tencoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
        "\tcenter = conv_block(encoder4_pool, 1024) # center\n",
        "\tdecoder4 = decoder_block(center, encoder4, 512) # 16\n",
        "\tdecoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
        "\tdecoder2 = decoder_block(decoder3, encoder2, 128) # 64\n",
        "\tdecoder1 = decoder_block(decoder2, encoder1, 64) # 128\n",
        "\tdecoder0 = decoder_block(decoder1, encoder0, 32) # 256\n",
        "\toutputs = layers.Conv2D(25, (1, 1), activation='softmax')(decoder0)\n",
        "\n",
        "\tmodel = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "\tmodel.compile(\n",
        "\t\toptimizer=optimizers.get(OPTIMIZER), \n",
        "\t\tloss=losses.get(LOSS),\n",
        "\t\tmetrics=[metrics.get(metric) for metric in METRICS])\n",
        "\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXK-0qM42UwP",
        "outputId": "40448c3a-e0a4-4940-93a9-2040510098d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 128, 128, 9  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 128, 128, 32  2624        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 128, 128, 32  128        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 128, 128, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 128, 128, 32  9248        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128, 128, 32  128        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 128, 128, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 64, 64, 32)   0           ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 64, 64, 64)   18496       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 64, 64, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 64, 64, 64)   36928       ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 64, 64, 64)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)  0           ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 32, 32, 128)  73856       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 128)  147584      ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 128)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 256)  295168      ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 256)  590080      ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 256)   0           ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 8, 8, 512)    1180160     ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 8, 8, 512)   2048        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 8, 8, 512)    0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 8, 8, 512)    2359808     ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 8, 8, 512)   2048        ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 8, 8, 512)    0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 512)   0           ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 4, 4, 1024)   4719616     ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 4, 4, 1024)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 4, 4, 1024)   9438208     ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 4, 4, 1024)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 8, 8, 512)   2097664     ['activation_11[0][0]']          \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8, 8, 1024)   0           ['activation_9[0][0]',           \n",
            "                                                                  'conv2d_transpose[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 8, 8, 1024)  4096        ['concatenate[0][0]']            \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 8, 8, 1024)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 8, 8, 512)    4719104     ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 8, 8, 512)    0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 8, 8, 512)    2359808     ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 8, 8, 512)    0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 16, 16, 256)  524544     ['activation_14[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 16, 16, 512)  0           ['activation_7[0][0]',           \n",
            "                                                                  'conv2d_transpose_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 512)  2048       ['concatenate_1[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 256)  1179904     ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 256)  590080      ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 128)  131200     ['activation_17[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 32, 32, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'conv2d_transpose_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 32, 32, 256)  1024       ['concatenate_2[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 32, 32, 128)  295040      ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 32, 32, 128)  512        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 32, 32, 128)  147584      ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 32, 32, 128)  512        ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 64, 64, 64)  32832       ['activation_20[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 64, 64, 128)  0           ['activation_3[0][0]',           \n",
            "                                                                  'conv2d_transpose_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 64, 64, 128)  512        ['concatenate_3[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 64, 64, 64)   73792       ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 64, 64, 64)  256         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 64, 64, 64)  256         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, 128, 128, 32  8224       ['activation_23[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 128, 128, 64  0           ['activation_1[0][0]',           \n",
            "                                )                                 'conv2d_transpose_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 128, 128, 64  256        ['concatenate_4[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_24[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 128, 128, 32  18464       ['activation_24[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 128, 128, 32  128        ['conv2d_20[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_25[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 128, 128, 32  9248        ['activation_25[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 128, 128, 32  128        ['conv2d_21[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_26[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 128, 128, 25  825         ['activation_26[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,129,017\n",
            "Trainable params: 31,113,017\n",
            "Non-trainable params: 16,000\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "m = get_model()\n",
        "print(m.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "G39jZYYX6B0E",
        "outputId": "8f29e7a6-a1a6-4a72-e766-21d76017823d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 463s 22s/step - loss: 0.0340 - root_mean_squared_error: 0.1845 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1821\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 426s 22s/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1819\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 436s 22s/step - loss: 0.0344 - root_mean_squared_error: 0.1854 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1819\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 427s 22s/step - loss: 0.0342 - root_mean_squared_error: 0.1850 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1818\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 426s 22s/step - loss: 0.0340 - root_mean_squared_error: 0.1843 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1818\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 425s 22s/step - loss: 0.0337 - root_mean_squared_error: 0.1837 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1817\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 425s 22s/step - loss: 0.0341 - root_mean_squared_error: 0.1847 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1817\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 381s 19s/step - loss: 0.0343 - root_mean_squared_error: 0.1852 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1817\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 376s 19s/step - loss: 0.0342 - root_mean_squared_error: 0.1848 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1817\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 426s 22s/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1817\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 378s 19s/step - loss: 0.0340 - root_mean_squared_error: 0.1843 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1817\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 425s 22s/step - loss: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1817\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 379s 19s/step - loss: 0.0336 - root_mean_squared_error: 0.1834 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 376s 19s/step - loss: 0.0345 - root_mean_squared_error: 0.1858 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 377s 19s/step - loss: 0.0341 - root_mean_squared_error: 0.1847 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 425s 22s/step - loss: 0.0340 - root_mean_squared_error: 0.1844 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 376s 19s/step - loss: 0.0340 - root_mean_squared_error: 0.1843 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 378s 19s/step - loss: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 378s 19s/step - loss: 0.0341 - root_mean_squared_error: 0.1848 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1815\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 423s 22s/step - loss: 0.0340 - root_mean_squared_error: 0.1843 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 377s 19s/step - loss: 0.0342 - root_mean_squared_error: 0.1850 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 425s 22s/step - loss: 0.0336 - root_mean_squared_error: 0.1834 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 424s 22s/step - loss: 0.0339 - root_mean_squared_error: 0.1841 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1816\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 424s 22s/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1817\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 423s 22s/step - loss: 0.0342 - root_mean_squared_error: 0.1850 - val_loss: 0.0330 - val_root_mean_squared_error: 0.1817\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 433s 22s/step - loss: 0.0343 - root_mean_squared_error: 0.1852 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1818\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 416s 21s/step - loss: 0.0340 - root_mean_squared_error: 0.1844 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1819\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 426s 22s/step - loss: 0.0339 - root_mean_squared_error: 0.1842 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1821\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 425s 22s/step - loss: 0.0339 - root_mean_squared_error: 0.1840 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1823\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 427s 22s/step - loss: 0.0337 - root_mean_squared_error: 0.1836 - val_loss: 0.0333 - val_root_mean_squared_error: 0.1825\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 424s 22s/step - loss: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1827\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 423s 22s/step - loss: 0.0338 - root_mean_squared_error: 0.1840 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1829\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 380s 19s/step - loss: 0.0342 - root_mean_squared_error: 0.1848 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1831\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 424s 22s/step - loss: 0.0338 - root_mean_squared_error: 0.1840 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1832\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 377s 19s/step - loss: 0.0337 - root_mean_squared_error: 0.1835 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1834\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 426s 22s/step - loss: 0.0337 - root_mean_squared_error: 0.1835 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1836\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 378s 19s/step - loss: 0.0337 - root_mean_squared_error: 0.1835 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1837\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 423s 22s/step - loss: 0.0342 - root_mean_squared_error: 0.1850 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1838\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 426s 22s/step - loss: 0.0335 - root_mean_squared_error: 0.1831 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1839\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 376s 19s/step - loss: 0.0341 - root_mean_squared_error: 0.1847 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1840\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 423s 22s/step - loss: 0.0339 - root_mean_squared_error: 0.1842 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1841\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 427s 22s/step - loss: 0.0335 - root_mean_squared_error: 0.1830 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1842\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 377s 19s/step - loss: 0.0338 - root_mean_squared_error: 0.1839 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1842\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 425s 22s/step - loss: 0.0341 - root_mean_squared_error: 0.1847 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 427s 22s/step - loss: 0.0336 - root_mean_squared_error: 0.1834 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 424s 22s/step - loss: 0.0337 - root_mean_squared_error: 0.1835 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 424s 22s/step - loss: 0.0339 - root_mean_squared_error: 0.1840 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 377s 19s/step - loss: 0.0340 - root_mean_squared_error: 0.1844 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 376s 19s/step - loss: 0.0332 - root_mean_squared_error: 0.1821 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 426s 22s/step - loss: 0.0338 - root_mean_squared_error: 0.1839 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 378s 19s/step - loss: 0.0337 - root_mean_squared_error: 0.1837 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1844\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 423s 22s/step - loss: 0.0335 - root_mean_squared_error: 0.1831 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1844\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 425s 22s/step - loss: 0.0339 - root_mean_squared_error: 0.1841 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 379s 19s/step - loss: 0.0334 - root_mean_squared_error: 0.1826 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 384s 20s/step - loss: 0.0338 - root_mean_squared_error: 0.1839 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 415s 21s/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 376s 19s/step - loss: 0.0339 - root_mean_squared_error: 0.1841 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 376s 19s/step - loss: 0.0335 - root_mean_squared_error: 0.1831 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1842\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 424s 22s/step - loss: 0.0338 - root_mean_squared_error: 0.1837 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1842\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 377s 19s/step - loss: 0.0332 - root_mean_squared_error: 0.1821 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1842\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 424s 22s/step - loss: 0.0339 - root_mean_squared_error: 0.1840 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1842\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 426s 22s/step - loss: 0.0335 - root_mean_squared_error: 0.1830 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1841\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 424s 22s/step - loss: 0.0338 - root_mean_squared_error: 0.1838 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1841\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 377s 19s/step - loss: 0.0333 - root_mean_squared_error: 0.1824 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1841\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 425s 22s/step - loss: 0.0338 - root_mean_squared_error: 0.1839 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1841\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 425s 22s/step - loss: 0.0336 - root_mean_squared_error: 0.1834 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1841\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 425s 22s/step - loss: 0.0332 - root_mean_squared_error: 0.1823 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1840\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 421s 22s/step - loss: 0.0335 - root_mean_squared_error: 0.1830 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1840\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 366s 19s/step - loss: 0.0332 - root_mean_squared_error: 0.1822 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1840\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 365s 19s/step - loss: 0.0340 - root_mean_squared_error: 0.1844 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1839\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 419s 21s/step - loss: 0.0333 - root_mean_squared_error: 0.1825 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1840\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 419s 21s/step - loss: 0.0336 - root_mean_squared_error: 0.1833 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1839\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 417s 21s/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1839\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 422s 22s/step - loss: 0.0335 - root_mean_squared_error: 0.1830 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1838\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 417s 21s/step - loss: 0.0335 - root_mean_squared_error: 0.1830 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1838\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 365s 19s/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1838\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 419s 21s/step - loss: 0.0333 - root_mean_squared_error: 0.1824 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1838\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 364s 19s/step - loss: 0.0333 - root_mean_squared_error: 0.1824 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1838\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 418s 21s/step - loss: 0.0333 - root_mean_squared_error: 0.1825 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1837\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 418s 21s/step - loss: 0.0336 - root_mean_squared_error: 0.1833 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1837\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 415s 21s/step - loss: 0.0332 - root_mean_squared_error: 0.1822 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1837\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 419s 21s/step - loss: 0.0336 - root_mean_squared_error: 0.1834 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1837\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 419s 21s/step - loss: 0.0336 - root_mean_squared_error: 0.1833 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1837\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 425s 22s/step - loss: 0.0328 - root_mean_squared_error: 0.1812 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1836\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 409s 21s/step - loss: 0.0333 - root_mean_squared_error: 0.1824 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1836\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 418s 21s/step - loss: 0.0327 - root_mean_squared_error: 0.1808 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1836\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 416s 21s/step - loss: 0.0340 - root_mean_squared_error: 0.1843 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1835\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 419s 21s/step - loss: 0.0330 - root_mean_squared_error: 0.1817 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1835\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 363s 19s/step - loss: 0.0333 - root_mean_squared_error: 0.1824 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1835\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 417s 21s/step - loss: 0.0334 - root_mean_squared_error: 0.1828 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1834\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 419s 21s/step - loss: 0.0333 - root_mean_squared_error: 0.1825 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1834\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 419s 21s/step - loss: 0.0330 - root_mean_squared_error: 0.1817 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1834\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0335 - root_mean_squared_error: 0.1830 "
          ]
        }
      ],
      "source": [
        "# m = get_model()\n",
        "# tf.keras.utils.plot_model(m)\n",
        "# Load a trained model. 50 epochs. 25 hours. Final RMSE ~0.08.\n",
        "MODEL_DIR = 'gs://' + BUCKET +'/'+ FOLDER +  '/'\n",
        "\n",
        "m = tf.keras.models.load_model(MODEL_DIR)\n",
        "# EPOCHS\n",
        "#int(TRAIN_SIZE / BATCH_SIZE)\n",
        "# m.fit(\n",
        "#     x=training, \n",
        "#     epochs=100, \n",
        "#     steps_per_epoch=20, \n",
        "#     validation_data=evaluation,\n",
        "#     validation_steps=EVAL_SIZE)\n",
        "\n",
        "# m.save('gs://' + BUCKET +'/'+ FOLDER +  '/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzM45ZQNvVnH"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}