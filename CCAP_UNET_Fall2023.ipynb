{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aml7hawaiiedu/CCAPLandCoverProject/blob/main/CCAP_UNET_Fall2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XfCSt4rxG490",
        "outputId": "c42e3ae9-c797-425a-c93a-a080b315bf27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio scikit-image tensorflow keras gdown\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "w8q0OqJ9MdDp",
        "outputId": "02db87e2-bac5-4ff7-fa78-46e9e753dc4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.8.post2-cp310-cp310-manylinux2014_x86_64.whl (20.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.7.22)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.23.5)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.5)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.8.post2 snuggs-1.4.7\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import gdown\n",
        "import zipfile\n",
        "import cv2\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shutil\n",
        "import rasterio\n",
        "import rasterio.plot\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras.utils import Sequence, to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "from skimage.util import random_noise\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage import label as nd_label\n",
        "from scipy.ndimage import generic_filter\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Additional code can be added here if needed"
      ],
      "metadata": {
        "id": "6IvzmnSDMqqQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory_path = '/content/image_subsets'\n",
        "os.makedirs(directory_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "u6DickGeN582"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Just unzip the first file to save time\n",
        "\n",
        "# zip_files = glob.glob('/content/drive/MyDrive/wetland_unet/UNET_Image_Chips/imagechip_trainingdata/*.zip')\n",
        "# extract_dir = '/content/image_subsets'  # destination directory\n",
        "\n",
        "# # Check if there are any matching zip files\n",
        "# if zip_files:\n",
        "#     # Select the first matching zip file\n",
        "#     first_zip_file = zip_files[0]\n",
        "\n",
        "#     # Extract the first zip file\n",
        "#     base_name = os.path.basename(first_zip_file)[:-4]\n",
        "#     unzip_dir = os.path.join(extract_dir, base_name)\n",
        "#     os.makedirs(unzip_dir, exist_ok=True)\n",
        "#     with zipfile.ZipFile(first_zip_file, 'r') as zip_ref:\n",
        "#         zip_ref.extractall(unzip_dir)\n",
        "\n",
        "#     print(f\"Extracted the first zip file: {first_zip_file}\")\n",
        "# else:\n",
        "#     print(\"No matching zip files found.\")\n"
      ],
      "metadata": {
        "id": "L29TbElKx6A-",
        "outputId": "fc27a7de-2cf2-43b5-fe9b-91d5c5cd4af6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted the first zip file: /content/drive/MyDrive/wetland_unet/UNET_Image_Chips/imagechip_trainingdata/Kauai_subset.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_files = glob.glob('/content/drive/MyDrive/wetland_unet/UNET_Image_Chips/imagechip_trainingdata/*.zip')\n",
        "extract_dir = '/content/image_subsets' # destination directory\n",
        "for zip_file in zip_files:\n",
        "    base_name = os.path.basename(zip_file)[:-4]\n",
        "    unzip_dir = os.path.join(extract_dir, base_name)\n",
        "    os.makedirs(unzip_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(unzip_dir)"
      ],
      "metadata": {
        "id": "CMmXtKr-s7QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_files = glob.glob('/content/drive/MyDrive/wetland_unet/UNET_Image_Chips/imagechip_trainingdata/*.csv')\n",
        "csv_list = []\n",
        "for csv_file in csv_files:\n",
        "    base_name = os.path.basename(csv_file)[:-4]\n",
        "    csv_dir = os.path.join(extract_dir, base_name)\n",
        "    base_csv = pd.read_csv(csv_file)\n",
        "    base_csv['subset'] = base_name\n",
        "    csv_list.append(base_csv)\n",
        "    index_csv = pd.concat(csv_list, ignore_index=True)"
      ],
      "metadata": {
        "id": "OHIwIVH5uLtH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# csv_files"
      ],
      "metadata": {
        "id": "5yz4whZOvMJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index_csv"
      ],
      "metadata": {
        "id": "Cuyf0HIBvLnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_rows_df = index_csv.groupby(['tif_name', 'label', 'subset']).size().reset_index(name='Count')\n",
        "unique_rows_df = index_csv.groupby(['tif_name', 'label', 'subset']).agg({'percent': 'mean'}).reset_index()"
      ],
      "metadata": {
        "id": "pYYNUe-22LQr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unique_rows_df"
      ],
      "metadata": {
        "id": "8l_TBihNwQf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df = unique_rows_df.pivot(index=['tif_name', 'subset'], columns='label', values='percent').reset_index().fillna(0)"
      ],
      "metadata": {
        "id": "9-ewXrj8jsS2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pivot_df"
      ],
      "metadata": {
        "id": "NKPgX0VdxBaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index_csv"
      ],
      "metadata": {
        "id": "u2r_mfu3xXkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = index_csv.merge(pivot_df, on=['tif_name', 'subset'], how='left')\n",
        "merged_df.drop(columns=['label'], inplace=True)"
      ],
      "metadata": {
        "id": "s6rnI3Quwdc2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_df"
      ],
      "metadata": {
        "id": "0Qd5C-G3wgdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_df = merged_df.drop_duplicates(subset=['tif_name', 'subset'])"
      ],
      "metadata": {
        "id": "hG9kwGPlxrKn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sum_df"
      ],
      "metadata": {
        "id": "m2dIvijAyXo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_rows = len(sum_df)\n",
        "train_fraction = 0.9 # modify this to set the training percentage\n",
        "train_rows = int(total_rows * train_fraction)\n",
        "val_rows = total_rows - train_rows\n",
        "\n",
        "random_assignment = np.array([0] * train_rows + [1] * val_rows)\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(random_assignment)\n",
        "sum_df['random_split'] = random_assignment"
      ],
      "metadata": {
        "id": "WSQZb3slylUq",
        "outputId": "514cd666-6266-4d62-887c-1a36fb2ed021",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-66bd3969d95d>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sum_df['random_split'] = random_assignment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agg_df = sum_df.groupby(['random_split']).agg({13: 'mean',14:'mean',15: 'mean',16:'mean',17: 'mean',18:'mean'}).reset_index()\n",
        "print(agg_df)"
      ],
      "metadata": {
        "id": "BhdSkVK-1UI8",
        "outputId": "e9e65310-9dd9-416a-adf5-1320abf9cfbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   random_split        13        14        15        16        17        18\n",
            "0             0  0.152032  0.034274  0.011877  0.001600  0.001068  0.001292\n",
            "1             1  0.145450  0.036990  0.009983  0.002517  0.001619  0.001482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum_df"
      ],
      "metadata": {
        "id": "Mo7NAKJwCUyt",
        "outputId": "df4c924e-42d2-4b58-f4be-4fb20df793d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      x_end  y_end  x_org  y_org    id           xmin           xmax  \\\n",
              "0      9217   1025   8705    513    61  438833.983073  440062.758637   \n",
              "1      9729   1025   9217    513    62  440062.834396  441291.605845   \n",
              "2     13825   1025  13313    513    70  449893.209832  451122.010258   \n",
              "5     15361   1025  14849    513    73  453579.566028  454808.362434   \n",
              "6      9217   1537   8705   1025   104  438833.962924  440062.791964   \n",
              "...     ...    ...    ...    ...   ...            ...            ...   \n",
              "6233  17921  15361  17409  14849  1079  308475.532176  309704.324054   \n",
              "6236   3585  15873   3073  15361  1087  274069.129264  275297.911026   \n",
              "6237   2049  16897   1537  16385  1156  270382.720297  271611.486128   \n",
              "6238  17409  16897  16897  16385  1186  307246.720617  308475.512807   \n",
              "6239  16897  17409  16385  16897  1221  306017.952151  307246.744778   \n",
              "\n",
              "              ymin          ymax   percent  ...                  subset  \\\n",
              "0     2.457574e+06  2.458802e+06  0.000919  ...          Kauai10_subset   \n",
              "1     2.457574e+06  2.458802e+06  0.033161  ...          Kauai10_subset   \n",
              "2     2.457574e+06  2.458802e+06  0.000130  ...          Kauai10_subset   \n",
              "5     2.457574e+06  2.458802e+06  0.001663  ...          Kauai10_subset   \n",
              "6     2.456345e+06  2.457574e+06  0.007381  ...          Kauai10_subset   \n",
              "...            ...           ...       ...  ...                     ...   \n",
              "6233  2.156737e+06  2.157966e+06  0.012070  ...  Hawaii_2010_008_subset   \n",
              "6236  2.155509e+06  2.156737e+06  0.000507  ...  Hawaii_2010_008_subset   \n",
              "6237  2.153051e+06  2.154280e+06  0.000847  ...  Hawaii_2010_008_subset   \n",
              "6238  2.153051e+06  2.154280e+06  0.000889  ...  Hawaii_2010_008_subset   \n",
              "6239  2.151822e+06  2.153051e+06  0.002216  ...  Hawaii_2010_008_subset   \n",
              "\n",
              "            13        14        15        16        17        18  \\\n",
              "0     0.000919  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "1     0.033161  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "2     0.000130  0.000137  0.003502  0.000000  0.000000  0.000000   \n",
              "5     0.000000  0.000000  0.001663  0.000000  0.000000  0.000000   \n",
              "6     0.007381  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "...        ...       ...       ...       ...       ...       ...   \n",
              "6233  0.000000  0.000000  0.000000  0.012070  0.000416  0.001926   \n",
              "6236  0.000000  0.000000  0.000507  0.000000  0.000000  0.000000   \n",
              "6237  0.000000  0.000000  0.000847  0.000000  0.000000  0.000000   \n",
              "6238  0.000000  0.000000  0.000000  0.000000  0.000000  0.000889   \n",
              "6239  0.000000  0.000000  0.000000  0.002216  0.000225  0.000000   \n",
              "\n",
              "      random_split                                        Images_path  \\\n",
              "0                0  /content/image_subsets/Kauai10_subset/Images/8...   \n",
              "1                1  /content/image_subsets/Kauai10_subset/Images/9...   \n",
              "2                0  /content/image_subsets/Kauai10_subset/Images/1...   \n",
              "5                0  /content/image_subsets/Kauai10_subset/Images/1...   \n",
              "6                0  /content/image_subsets/Kauai10_subset/Images/8...   \n",
              "...            ...                                                ...   \n",
              "6233             0  /content/image_subsets/Hawaii_2010_008_subset/...   \n",
              "6236             0  /content/image_subsets/Hawaii_2010_008_subset/...   \n",
              "6237             0  /content/image_subsets/Hawaii_2010_008_subset/...   \n",
              "6238             0  /content/image_subsets/Hawaii_2010_008_subset/...   \n",
              "6239             1  /content/image_subsets/Hawaii_2010_008_subset/...   \n",
              "\n",
              "                                            Labels_path  \n",
              "0     /content/image_subsets/Kauai10_subset/Labels/8...  \n",
              "1     /content/image_subsets/Kauai10_subset/Labels/9...  \n",
              "2     /content/image_subsets/Kauai10_subset/Labels/1...  \n",
              "5     /content/image_subsets/Kauai10_subset/Labels/1...  \n",
              "6     /content/image_subsets/Kauai10_subset/Labels/8...  \n",
              "...                                                 ...  \n",
              "6233  /content/image_subsets/Hawaii_2010_008_subset/...  \n",
              "6236  /content/image_subsets/Hawaii_2010_008_subset/...  \n",
              "6237  /content/image_subsets/Hawaii_2010_008_subset/...  \n",
              "6238  /content/image_subsets/Hawaii_2010_008_subset/...  \n",
              "6239  /content/image_subsets/Hawaii_2010_008_subset/...  \n",
              "\n",
              "[3244 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-912d56c4-6545-4691-a999-83d877284626\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x_end</th>\n",
              "      <th>y_end</th>\n",
              "      <th>x_org</th>\n",
              "      <th>y_org</th>\n",
              "      <th>id</th>\n",
              "      <th>xmin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymin</th>\n",
              "      <th>ymax</th>\n",
              "      <th>percent</th>\n",
              "      <th>...</th>\n",
              "      <th>subset</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>random_split</th>\n",
              "      <th>Images_path</th>\n",
              "      <th>Labels_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9217</td>\n",
              "      <td>1025</td>\n",
              "      <td>8705</td>\n",
              "      <td>513</td>\n",
              "      <td>61</td>\n",
              "      <td>438833.983073</td>\n",
              "      <td>440062.758637</td>\n",
              "      <td>2.457574e+06</td>\n",
              "      <td>2.458802e+06</td>\n",
              "      <td>0.000919</td>\n",
              "      <td>...</td>\n",
              "      <td>Kauai10_subset</td>\n",
              "      <td>0.000919</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/image_subsets/Kauai10_subset/Images/8...</td>\n",
              "      <td>/content/image_subsets/Kauai10_subset/Labels/8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9729</td>\n",
              "      <td>1025</td>\n",
              "      <td>9217</td>\n",
              "      <td>513</td>\n",
              "      <td>62</td>\n",
              "      <td>440062.834396</td>\n",
              "      <td>441291.605845</td>\n",
              "      <td>2.457574e+06</td>\n",
              "      <td>2.458802e+06</td>\n",
              "      <td>0.033161</td>\n",
              "      <td>...</td>\n",
              "      <td>Kauai10_subset</td>\n",
              "      <td>0.033161</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/image_subsets/Kauai10_subset/Images/9...</td>\n",
              "      <td>/content/image_subsets/Kauai10_subset/Labels/9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13825</td>\n",
              "      <td>1025</td>\n",
              "      <td>13313</td>\n",
              "      <td>513</td>\n",
              "      <td>70</td>\n",
              "      <td>449893.209832</td>\n",
              "      <td>451122.010258</td>\n",
              "      <td>2.457574e+06</td>\n",
              "      <td>2.458802e+06</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>...</td>\n",
              "      <td>Kauai10_subset</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.003502</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/image_subsets/Kauai10_subset/Images/1...</td>\n",
              "      <td>/content/image_subsets/Kauai10_subset/Labels/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>15361</td>\n",
              "      <td>1025</td>\n",
              "      <td>14849</td>\n",
              "      <td>513</td>\n",
              "      <td>73</td>\n",
              "      <td>453579.566028</td>\n",
              "      <td>454808.362434</td>\n",
              "      <td>2.457574e+06</td>\n",
              "      <td>2.458802e+06</td>\n",
              "      <td>0.001663</td>\n",
              "      <td>...</td>\n",
              "      <td>Kauai10_subset</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/image_subsets/Kauai10_subset/Images/1...</td>\n",
              "      <td>/content/image_subsets/Kauai10_subset/Labels/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9217</td>\n",
              "      <td>1537</td>\n",
              "      <td>8705</td>\n",
              "      <td>1025</td>\n",
              "      <td>104</td>\n",
              "      <td>438833.962924</td>\n",
              "      <td>440062.791964</td>\n",
              "      <td>2.456345e+06</td>\n",
              "      <td>2.457574e+06</td>\n",
              "      <td>0.007381</td>\n",
              "      <td>...</td>\n",
              "      <td>Kauai10_subset</td>\n",
              "      <td>0.007381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/image_subsets/Kauai10_subset/Images/8...</td>\n",
              "      <td>/content/image_subsets/Kauai10_subset/Labels/8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6233</th>\n",
              "      <td>17921</td>\n",
              "      <td>15361</td>\n",
              "      <td>17409</td>\n",
              "      <td>14849</td>\n",
              "      <td>1079</td>\n",
              "      <td>308475.532176</td>\n",
              "      <td>309704.324054</td>\n",
              "      <td>2.156737e+06</td>\n",
              "      <td>2.157966e+06</td>\n",
              "      <td>0.012070</td>\n",
              "      <td>...</td>\n",
              "      <td>Hawaii_2010_008_subset</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012070</td>\n",
              "      <td>0.000416</td>\n",
              "      <td>0.001926</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/image_subsets/Hawaii_2010_008_subset/...</td>\n",
              "      <td>/content/image_subsets/Hawaii_2010_008_subset/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6236</th>\n",
              "      <td>3585</td>\n",
              "      <td>15873</td>\n",
              "      <td>3073</td>\n",
              "      <td>15361</td>\n",
              "      <td>1087</td>\n",
              "      <td>274069.129264</td>\n",
              "      <td>275297.911026</td>\n",
              "      <td>2.155509e+06</td>\n",
              "      <td>2.156737e+06</td>\n",
              "      <td>0.000507</td>\n",
              "      <td>...</td>\n",
              "      <td>Hawaii_2010_008_subset</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000507</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/image_subsets/Hawaii_2010_008_subset/...</td>\n",
              "      <td>/content/image_subsets/Hawaii_2010_008_subset/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6237</th>\n",
              "      <td>2049</td>\n",
              "      <td>16897</td>\n",
              "      <td>1537</td>\n",
              "      <td>16385</td>\n",
              "      <td>1156</td>\n",
              "      <td>270382.720297</td>\n",
              "      <td>271611.486128</td>\n",
              "      <td>2.153051e+06</td>\n",
              "      <td>2.154280e+06</td>\n",
              "      <td>0.000847</td>\n",
              "      <td>...</td>\n",
              "      <td>Hawaii_2010_008_subset</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000847</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/image_subsets/Hawaii_2010_008_subset/...</td>\n",
              "      <td>/content/image_subsets/Hawaii_2010_008_subset/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6238</th>\n",
              "      <td>17409</td>\n",
              "      <td>16897</td>\n",
              "      <td>16897</td>\n",
              "      <td>16385</td>\n",
              "      <td>1186</td>\n",
              "      <td>307246.720617</td>\n",
              "      <td>308475.512807</td>\n",
              "      <td>2.153051e+06</td>\n",
              "      <td>2.154280e+06</td>\n",
              "      <td>0.000889</td>\n",
              "      <td>...</td>\n",
              "      <td>Hawaii_2010_008_subset</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000889</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/image_subsets/Hawaii_2010_008_subset/...</td>\n",
              "      <td>/content/image_subsets/Hawaii_2010_008_subset/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6239</th>\n",
              "      <td>16897</td>\n",
              "      <td>17409</td>\n",
              "      <td>16385</td>\n",
              "      <td>16897</td>\n",
              "      <td>1221</td>\n",
              "      <td>306017.952151</td>\n",
              "      <td>307246.744778</td>\n",
              "      <td>2.151822e+06</td>\n",
              "      <td>2.153051e+06</td>\n",
              "      <td>0.002216</td>\n",
              "      <td>...</td>\n",
              "      <td>Hawaii_2010_008_subset</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002216</td>\n",
              "      <td>0.000225</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/image_subsets/Hawaii_2010_008_subset/...</td>\n",
              "      <td>/content/image_subsets/Hawaii_2010_008_subset/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3244 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-912d56c4-6545-4691-a999-83d877284626')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-912d56c4-6545-4691-a999-83d877284626 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-912d56c4-6545-4691-a999-83d877284626');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-366a080a-ebff-4023-84f2-02d184f31708\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-366a080a-ebff-4023-84f2-02d184f31708')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-366a080a-ebff-4023-84f2-02d184f31708 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum_df['Images_path']=\"/content/image_subsets/\"+sum_df['subset']+'/Images/'+sum_df['tif_name']\n",
        "sum_df['Labels_path']=\"/content/image_subsets/\"+sum_df['subset']+'/Labels/'+sum_df['tif_name']"
      ],
      "metadata": {
        "id": "CT5lBLaAFtSu",
        "outputId": "10bbc8ac-42fd-453e-d298-163cdca9b7de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-734faffeae8c>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sum_df['Images_path']=\"/content/image_subsets/\"+sum_df['subset']+'/Images/'+sum_df['tif_name']\n",
            "<ipython-input-19-734faffeae8c>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sum_df['Labels_path']=\"/content/image_subsets/\"+sum_df['subset']+'/Labels/'+sum_df['tif_name']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sum_df"
      ],
      "metadata": {
        "id": "OAL5urmZyymq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data from geotiff files\n",
        "def load_data(files):\n",
        "    data = []\n",
        "    for file in files:\n",
        "        with rasterio.open(file) as src:\n",
        "            band_data = []\n",
        "            for band in src.read():\n",
        "                band_data.append(band)\n",
        "            data.append(np.dstack(band_data))\n",
        "    return np.array(data)"
      ],
      "metadata": {
        "id": "ykbrnRUW_J1F"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load_data([i for i in  sum_df['Images_path'][0:5]])"
      ],
      "metadata": {
        "id": "bl1tswrFBMX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example to show the width, height and bands of the images\n",
        "def get_image_shapes_in_folders(folder_paths):\n",
        "    image_shapes = []\n",
        "    for folder_path in folder_paths:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            # Sort the files alphabetically\n",
        "            files = sorted(files)\n",
        "            for file in files:\n",
        "                if file.endswith('.tif') or file.endswith('.jpg') or file.endswith('.png'):\n",
        "                    image_path = os.path.join(root, file)\n",
        "                    try:\n",
        "                        with rasterio.open(image_path) as src:\n",
        "                            width, height = src.width, src.height\n",
        "                            band_count = src.count  # Number of bands in the image\n",
        "                            image_shapes.append((file, width, height, band_count))\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error getting shape of image '{file}': {e}\")\n",
        "    return image_shapes\n",
        "\n",
        "folder_paths = [\"/content/image_subsets/Kauai_subset/Images\"]\n",
        "\n",
        "shapes = get_image_shapes_in_folders(folder_paths)\n",
        "for shape in shapes:\n",
        "    file, width, height, band_count = shape\n",
        "    print(f\" {file[:-4]}: {width}, {height}, {band_count}\")"
      ],
      "metadata": {
        "id": "4UqK2FHq40qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_reshape_image(image_path, img_height, img_width):\n",
        "    with rasterio.open(image_path) as src:\n",
        "        image = src.read()\n",
        "        return image"
      ],
      "metadata": {
        "id": "QUS8UV5x_NAi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [load_and_reshape_image(i,512,512) for i in sum_df['Labels_path'][0:5]]"
      ],
      "metadata": {
        "id": "Mpg8plmIJnIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this function takes the following arguments:\n",
        "image_files: A list of file paths to image files.\n",
        "\n",
        "*   label_files: A list of file paths to label files.\n",
        "*   img_height: The desired height for the images.\n",
        "*   img_width: The desired width for the images.\n",
        "*   num_classes: The number of classes for one-hot encoding."
      ],
      "metadata": {
        "id": "VayjXBQb0KKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_and_labels(image_files, label_files, img_height, img_width, num_classes):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  # image_files = glob.glob(os.path.join(image_files, \"*.tif\"))\n",
        "  for image_file in image_files:\n",
        "      image = load_and_reshape_image(image_file, img_height, img_width)\n",
        "      images.append(image)\n",
        "\n",
        "  # label_files = glob.glob(os.path.join(label_files, \"*.tif\"))\n",
        "  for label_file in label_files:\n",
        "      label = load_and_reshape_image(label_file, img_height, img_width)\n",
        "      label -= 1  # adjust labels to be in the range 0-8 instead of 1-9\n",
        "      label = to_categorical(label, num_classes=num_classes)   # one-hot encode the labels\n",
        "      labels.append(label)\n",
        "\n",
        "  return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "ZCase72Y_k6J"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load_images_and_labels(sum_df['Images_path'][0:5], sum_df['Labels_path'][0:5],512,512,21)"
      ],
      "metadata": {
        "id": "A1nRLa1WKMZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, image_files, label_files, img_height, img_width, batch_size, num_classes):\n",
        "        self.image_files = image_files\n",
        "        self.label_files = label_files\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        # self.noise = noise\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_files) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_files = self.image_files[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        batch_images, batch_labels = self.load_images_and_labels(batch_files)\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "    def load_and_reshape_image(self, image_path):\n",
        "        with rasterio.open(image_path) as src:\n",
        "            image = src.read()\n",
        "            image = image.transpose((1, 2, 0))\n",
        "            if image.shape[0] != self.img_height or image.shape[1] != self.img_width:\n",
        "                image = cv2.resize(image, (self.img_width, self.img_height), interpolation=cv2.INTER_NEAREST)\n",
        "            if len(image.shape) == 3 and image.shape[2] == 1:\n",
        "                image = np.squeeze(image, axis=2)\n",
        "\n",
        "            return image\n",
        "\n",
        "    def load_images_and_labels(self, image_files):\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for image_file in image_files:\n",
        "            image = self.load_and_reshape_image(image_file)\n",
        "            image[image <= -3e+38] = np.nan\n",
        "\n",
        "            # # Replace NaN values with the mean of the non-NaN pixels\n",
        "            if np.any(np.isnan(image)):\n",
        "                nan_mask = np.isnan(image)\n",
        "                image[nan_mask] = np.nanmean(image)\n",
        "\n",
        "            # # Replace Inf values with the mean of the non-Inf pixels\n",
        "            if np.any(np.isinf(image)):\n",
        "                inf_mask = np.isinf(image)\n",
        "                image[inf_mask] = np.nanmean(image)\n",
        "\n",
        "            # Convert to float\n",
        "            image = image.astype(np.float32)\n",
        "\n",
        "            # # Z-score normalization\n",
        "            # mean = np.mean(image, axis=(0, 1), keepdims=True)\n",
        "            # std = np.std(image, axis=(0, 1), keepdims=True)\n",
        "            # # mean[mean < 0]\n",
        "            # std[std < 0] = 0\n",
        "\n",
        "            # # Normalize with epsilon to prevent divide by zero\n",
        "            # epsilon = 1e-7\n",
        "\n",
        "            # image = (image - mean) / (std + epsilon)\n",
        "\n",
        "            images.append(image)\n",
        "\n",
        "        for image_file in image_files:\n",
        "            label_file = image_file.replace(\"Images\", \"Labels\")\n",
        "            label = self.load_and_reshape_image(label_file)\n",
        "            label -= 1\n",
        "            label = to_categorical(label, num_classes=self.num_classes)\n",
        "            labels.append(label)\n",
        "\n",
        "        return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "rEDVI98o_0np"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import TenserFlow classes and functions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "S63ow1ZD2ePc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "# from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "\n",
        "# from tensorflow.keras.layers import BatchNormalization\n",
        "# from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "# from tensorflow.python.keras.layers import BatchNormalization\n",
        "\n",
        "# U-Net model for image segmentation.\n",
        "# Encoder and decoder conncted by a center block.\n",
        "# Encoder downsamples the input image while capturing its features.\n",
        "# Decoder upsamples the encoded image to generate a segmentation map.\n",
        "\n",
        "def conv_block(input_tensor, num_filters):\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('LeakyReLU')(encoder) # from relu to LeakyReLU\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('LeakyReLU')(encoder) # from relu to LeakyReLU\n",
        "\treturn encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "\tencoder = conv_block(input_tensor, num_filters)\n",
        "\tencoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "\treturn encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "\tdecoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "\tdecoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('LeakyReLU')(decoder) # from relu to LeakyReLU\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('LeakyReLU')(decoder) # from relu to LeakyReLU\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('LeakyReLU')(decoder) # from relu to LeakyReLU\n",
        "\treturn decoder\n",
        "\n",
        "def get_model():\n",
        "\tinputs = layers.Input(shape=[KERNEL_SIZE, KERNEL_SIZE, len(BANDS)]) # 256\n",
        "\tencoder0_pool, encoder0 = encoder_block(inputs, 32) # 128\n",
        "\tencoder1_pool, encoder1 = encoder_block(encoder0_pool, 64) # 64\n",
        "\tencoder2_pool, encoder2 = encoder_block(encoder1_pool, 128) # 32\n",
        "\tencoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
        "\tencoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
        "\tcenter = conv_block(encoder4_pool, 1024) # center\n",
        "\tdecoder4 = decoder_block(center, encoder4, 512) # 16\n",
        "\tdecoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
        "\tdecoder2 = decoder_block(decoder3, encoder2, 128) # 64\n",
        "\tdecoder1 = decoder_block(decoder2, encoder1, 64) # 128\n",
        "\tdecoder0 = decoder_block(decoder1, encoder0, 32) # 256\n",
        "\toutputs = layers.Conv2D(25, (1, 1), activation='softmax')(decoder0) # kept because this is a multiclass classification\n",
        "\n",
        "\tmodel = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "\tmodel.compile(\n",
        "\t\toptimizer=optimizers.get(OPTIMIZER),\n",
        "\t\tloss=losses.get(LOSS),\n",
        "\t\tmetrics=[metrics.get(metric) for metric in METRICS])\n",
        "\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "R9gKYuRQMUM2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=(img_size[0], img_size[1], 4))  # Change the number of channels to 4\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"LeakyReLU\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = layers.Activation(\"LeakyReLU\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"LeakyReLU\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = layers.Activation(\"LeakyReLU\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"LeakyReLU\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # updated to sparse categorical cross-entropy loss\n",
        "    return model"
      ],
      "metadata": {
        "id": "06iTebsEACQu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_save_segments(input_folder, output_folder, model, img_height, img_width):\n",
        "      # Create output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Get a list of input files\n",
        "    input_files = [f for f in os.listdir(input_folder) if f.endswith('.tif')]\n",
        "\n",
        "    for filename in input_files:\n",
        "              # Read input image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "\n",
        "        with rasterio.open(image_path) as src:\n",
        "            # Read image data and reshape\n",
        "            image = src.read()  # Read all bands\n",
        "\n",
        "        image = load_and_reshape_image(image_path,img_height, img_width)\n",
        "        image = image.astype(np.uint8)\n",
        "        # print(image.shape)\n",
        "        masks = mask_generator.generate(image)\n",
        "\n",
        "        flat_mask = show_anns(masks)\n",
        "        imagery_file = rasterio.open(image_path)\n",
        "        imagery_transform = imagery_file.transform\n",
        "        reshaped_image = rasterio.plot.reshape_as_raster(flat_mask)\n",
        "        reshaped_image = reshaped_image[0]\n",
        "        # Get metadata from the input image\n",
        "        # print(reshaped_image.shape)\n",
        "        meta = src.meta\n",
        "\n",
        "        # Update metadata for the output image\n",
        "        meta.update(count=1, dtype=reshaped_image.dtype)\n",
        "\n",
        "        # Create output path\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "        # Write all 9 prediction channels as separate bands\n",
        "        with rasterio.open(output_path, 'w', **meta) as dst:\n",
        "            # for i in range(9):\n",
        "            dst.write(reshaped_image,1)  # Write each channel as a separate band\n",
        "\n",
        "        print(f\"Saved prediction for {filename}\")\n",
        "\n",
        "    print(\"Prediction and saving completed.\")"
      ],
      "metadata": {
        "id": "k685DpwEAEzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_save(input_folder, output_folder, model, img_height, img_width):\n",
        "    # Create output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Get a list of input files\n",
        "    input_files = [f for f in os.listdir(input_folder) if f.endswith('.tif')]\n",
        "\n",
        "    for filename in input_files:\n",
        "        # Read input image\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        with rasterio.open(input_path) as src:\n",
        "            # Read image data and reshape\n",
        "            image = src.read()  # Read all bands\n",
        "\n",
        "            image[image <= -3e+38] = np.nan\n",
        "\n",
        "            # # Replace NaN values with the mean of the non-NaN pixels\n",
        "            if np.any(np.isnan(image)):\n",
        "                nan_mask = np.isnan(image)\n",
        "                image[nan_mask] = np.nanmean(image)\n",
        "\n",
        "            # # Replace Inf values with the mean of the non-Inf pixels\n",
        "            if np.any(np.isinf(image)):\n",
        "                inf_mask = np.isinf(image)\n",
        "                image[inf_mask] = np.nanmean(image)\n",
        "\n",
        "            # Convert to float\n",
        "            image = image.astype(np.float32)\n",
        "\n",
        "            # # Z-score normalization\n",
        "            # mean = np.mean(image, axis=(0, 1), keepdims=True)\n",
        "            # std = np.std(image, axis=(0, 1), keepdims=True)\n",
        "            # # mean[mean < 0]\n",
        "            # std[std < 0] = 0\n",
        "\n",
        "            # # Normalize with epsilon to prevent divide by zero\n",
        "            # epsilon = 1e-7\n",
        "\n",
        "            # image = (image - mean) / (std + epsilon)\n",
        "\n",
        "            image = np.transpose(image, (1, 2, 0))  # Transpose to (height, width, bands)\n",
        "            image = cv2.resize(image, (img_width, img_height), interpolation=cv2.INTER_NEAREST)\n",
        "            image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "            # # Perform prediction\n",
        "            prediction = model.predict(image)\n",
        "            prediction[prediction <= 0] = np.nan\n",
        "            prediction = prediction*255\n",
        "            prediction = prediction.astype(np.uint8)\n",
        "\n",
        "        # Get metadata from the input image\n",
        "        meta = src.meta\n",
        "\n",
        "        # Update metadata for the output image\n",
        "        meta.update(count=26, dtype=prediction.dtype,nodata = 0)\n",
        "        # meta.\n",
        "        # Create output path\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "        # Write all 9 prediction channels as separate bands\n",
        "        with rasterio.open(output_path, 'w', **meta) as dst:\n",
        "            for i in range(25):\n",
        "                dst.write(prediction[0, :, :, i], i + 1)  # Write each channel as a separate band\n",
        "\n",
        "            # Add a 10th band containing the argmax of the 9 channels\n",
        "            argmax_band = np.argmax(prediction[0], axis=-1)\n",
        "            dst.write(argmax_band, 26)\n",
        "\n",
        "        print(f\"Saved prediction for {filename}\")\n",
        "\n",
        "    print(\"Prediction and saving completed.\")"
      ],
      "metadata": {
        "id": "6Z-mnFB7AL-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KERNEL_SIZE = 512\n",
        "BANDS = range(7)\n",
        "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
        "OPTIMIZER = 'adam'\n",
        "LOSS = 'categorical_crossentropy'\n",
        "METRICS = ['categorical_accuracy']\n",
        "\n"
      ],
      "metadata": {
        "id": "JFpe-4LAd0wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "# print(model.summary())"
      ],
      "metadata": {
        "id": "bnphYPbeNKgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict_and_save(input_folder, output_folder, model, img_height, img_width)\n",
        "predict_and_save('/content/image_subsets/Kauai_subset/Images/', '/content/Kauai_Predicts/', model, 512, 512)"
      ],
      "metadata": {
        "id": "dlus2_HlMzoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c666986f-7562-4115-b82c-656b5934602c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 11s 11s/step\n",
            "Saved prediction for 10241_1537.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 17921_1537.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 9217_6145.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 9217_8193.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 13825_3073.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 18433_8705.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 8193_10241.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 10753_6145.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 16897_1025.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 20481_7169.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 3585_12289.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 10753_7169.tif\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Saved prediction for 8193_9729.tif\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Saved prediction for 13825_11265.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 10753_2561.tif\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Saved prediction for 5633_12801.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 8193_3585.tif\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Saved prediction for 18945_2561.tif\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Saved prediction for 6657_10753.tif\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Saved prediction for 14849_8705.tif\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "Saved prediction for 10753_6657.tif\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Saved prediction for 9217_513.tif\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Saved prediction for 10753_1025.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 12801_4609.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 14337_8193.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 11265_4097.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 8193_7169.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 16385_8193.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 10241_8193.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 19969_7169.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 17409_2561.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 8705_4097.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 17921_13825.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 17921_3073.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 8193_15873.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 8705_8193.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 18433_8193.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 19457_3073.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 8193_14849.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 16897_8193.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 6145_13825.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 14849_12801.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 14337_11777.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 18945_12289.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 8193_5633.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 17921_13313.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 12801_8193.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 7681_15361.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 5633_13825.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 18433_13825.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 16385_13825.tif\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "Saved prediction for 8705_4609.tif\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Saved prediction for 12289_6657.tif\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Saved prediction for 7169_13313.tif\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "Saved prediction for 19457_10753.tif\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Saved prediction for 20481_6657.tif\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Saved prediction for 17921_12801.tif\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Saved prediction for 19457_11265.tif\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Saved prediction for 9729_7169.tif\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Saved prediction for 9729_7681.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 17921_10753.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 14849_15873.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 19457_5633.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 14337_12289.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 16897_9217.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 16897_12801.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 12289_4097.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 19969_2561.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 18433_10753.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 14849_14849.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 5633_11777.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 8193_8193.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 17409_7169.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 7681_5633.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 10753_15873.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 13313_2049.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 19969_8705.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 5633_13313.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 13313_513.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 16385_9729.tif\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Saved prediction for 11777_12801.tif\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Saved prediction for 20993_4609.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 14849_513.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 8705_5633.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 10753_3073.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 14849_1025.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 18433_9217.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 9217_4609.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 18945_7169.tif\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Saved prediction for 10241_7169.tif\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Saved prediction for 6145_9729.tif\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Saved prediction for 12289_16385.tif\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Saved prediction for 13313_1537.tif\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Saved prediction for 11777_5121.tif\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Saved prediction for 18945_11265.tif\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Saved prediction for 18945_6657.tif\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Saved prediction for 20481_6145.tif\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Saved prediction for 17409_11777.tif\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Saved prediction for 8705_7681.tif\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Saved prediction for 20993_4097.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 19457_7169.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 16385_9217.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 5633_10753.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 7169_15361.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 5633_12289.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 17921_9217.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 18433_12801.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 20481_5121.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 8705_10241.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 17921_2561.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 11265_1537.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 11777_16385.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 17409_1025.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 11777_8193.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 20481_4609.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 15361_1025.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 18433_3073.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 15873_14849.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 20481_5633.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 12801_1025.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 10753_3585.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 7681_15873.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 20481_4097.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 10241_7681.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 7681_5121.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 9217_7169.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 19457_9729.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 11265_7169.tif\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Saved prediction for 9217_5633.tif\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Saved prediction for 12289_9217.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 12801_1537.tif\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Saved prediction for 19457_6657.tif\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Saved prediction for 9217_1025.tif\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Saved prediction for 15873_8705.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 12289_14849.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 16897_10241.tif\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Saved prediction for 10753_1537.tif\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Saved prediction for 12801_8705.tif\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "Saved prediction for 17921_2049.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 11777_7681.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 13825_6145.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 15873_3073.tif\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Saved prediction for 18945_7681.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 8193_4097.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 15873_13313.tif\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Saved prediction for 7681_12801.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 13825_13313.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 19457_2049.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 7169_11265.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 8193_4609.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 9729_4609.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 12289_4609.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 12801_15361.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 9729_8193.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 21284_4609.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 10241_2049.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 6657_11265.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 17921_8705.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 9729_1025.tif\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Saved prediction for 18433_10241.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 12289_7681.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 13313_15361.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 13825_3585.tif\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Saved prediction for 13825_12801.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 8705_7169.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 14337_14337.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 12801_5121.tif\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Saved prediction for 17409_3585.tif\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Saved prediction for 7681_3585.tif\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Saved prediction for 11265_7681.tif\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Saved prediction for 17409_8705.tif\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Saved prediction for 16897_12289.tif\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Saved prediction for 14849_10753.tif\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Saved prediction for 9729_4097.tif\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "Saved prediction for 15361_8193.tif\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Saved prediction for 10753_4609.tif\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Saved prediction for 10241_6657.tif\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Saved prediction for 13825_15361.tif\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Saved prediction for 11777_4609.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 16385_8705.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 12289_5121.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 9217_5121.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 17409_7681.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 8705_1025.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 9729_5121.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 12289_8193.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 14337_3585.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 14849_9217.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 19969_5121.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 18945_6145.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 5121_10241.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 15873_9217.tif\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Saved prediction for 5633_9729.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 5633_10241.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 19969_5633.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 18945_11777.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 12289_1025.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 8705_5121.tif\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Saved prediction for 18945_9729.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 13825_14849.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 19969_7681.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 11777_2049.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 9217_7681.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 20993_6145.tif\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Saved prediction for 7681_10241.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 9729_6145.tif\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Saved prediction for 5121_10753.tif\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Saved prediction for 12289_2049.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 16385_15361.tif\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Saved prediction for 10753_2049.tif\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Saved prediction for 14337_12801.tif\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Saved prediction for 7169_4609.tif\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Saved prediction for 6145_11777.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 14337_11265.tif\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Saved prediction for 17921_11265.tif\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Saved prediction for 17921_3585.tif\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Saved prediction for 18433_2561.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 3585_11777.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 17921_8193.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 13313_14849.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 18945_8705.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 8193_6657.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 13825_5633.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 7169_10753.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 18945_9217.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 19969_8193.tif\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Saved prediction for 18433_7681.tif\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Saved prediction for 19457_8193.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 12289_15873.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 18945_10753.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 6657_14849.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 7681_4609.tif\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Saved prediction for 17921_7681.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 18945_12801.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 7681_11265.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 14849_15361.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 17921_10241.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 8193_12289.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 13825_13825.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 15361_15873.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 10241_1025.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 12289_11777.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 14337_10753.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 13825_2049.tif\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Saved prediction for 17409_10241.tif\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Saved prediction for 12801_7169.tif\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Saved prediction for 7169_14849.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 17921_11777.tif\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Saved prediction for 513_10241.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 17921_9729.tif\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Saved prediction for 15361_15361.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 12289_1537.tif\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Saved prediction for 9729_15873.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 6657_12801.tif\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Saved prediction for 16897_2049.tif\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Saved prediction for 10241_2561.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 8193_5121.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 16897_8705.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 10753_7681.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 21284_5633.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 11777_1537.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 6657_4609.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 11265_6657.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 9217_3585.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 19969_6657.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 8193_7681.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 11777_4097.tif\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Saved prediction for 14849_14337.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 16897_2561.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 12801_2049.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 19457_7681.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 12289_12289.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 14849_11265.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 15873_9729.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 12289_15361.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 11265_1025.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 11265_14337.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 19969_6145.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 15361_9217.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 19457_9217.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 11777_7169.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 15361_1537.tif\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Saved prediction for 19457_10241.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 6145_12801.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 14849_8193.tif\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Saved prediction for 8705_6657.tif\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Saved prediction for 15361_12801.tif\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "Saved prediction for 8705_14849.tif\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "Saved prediction for 13313_15873.tif\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Saved prediction for 9729_5633.tif\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Saved prediction for 16897_11777.tif\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Saved prediction for 9217_6657.tif\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Saved prediction for 19457_8705.tif\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Saved prediction for 8705_513.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 16897_13825.tif\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Saved prediction for 18433_1537.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 14337_2561.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 20993_5633.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 5121_11777.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 13825_12289.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 15361_11265.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 14337_14849.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 18433_11777.tif\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Saved prediction for 9729_6657.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 15361_13825.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 18433_13313.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 9217_14849.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 6657_11777.tif\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Saved prediction for 14337_4097.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 7169_4097.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 9217_3073.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 17409_13825.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 18433_7169.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 11265_3585.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 15361_12289.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 6657_14337.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 18945_5121.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 15361_10753.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 6145_12289.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 10241_6145.tif\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Saved prediction for 16897_1537.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 12801_7681.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 15873_3585.tif\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Saved prediction for 11777_12289.tif\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Saved prediction for 19457_5121.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 10241_5633.tif\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Saved prediction for 5121_11265.tif\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Saved prediction for 6657_12289.tif\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Saved prediction for 18945_8193.tif\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Saved prediction for 17921_12289.tif\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Saved prediction for 7681_4097.tif\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Saved prediction for 13825_4097.tif\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Saved prediction for 13825_5121.tif\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "Saved prediction for 15361_8705.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 12289_8705.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 10753_14849.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 13825_2561.tif\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Saved prediction for 15873_13825.tif\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Saved prediction for 17409_9729.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 17409_13313.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 19969_3073.tif\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Saved prediction for 12289_7169.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 17409_11265.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 13825_1537.tif\n",
            "Prediction and saving completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sum_df"
      ],
      "metadata": {
        "id": "bPY2fsZ2ZCSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_gen_test = DataGenerator(sum_df['Images_path'][0:5], sum_df['Labels_path'][0:5], 512, 512, 2, 22)\n",
        "# Create the data generator\n",
        "training_data_generator = DataGenerator(sum_df['Images_path'][sum_df['random_split']==0], sum_df['Labels_path'][sum_df['random_split']==0], 512, 512, 4, 25)\n",
        "validation_data_generator = DataGenerator(sum_df['Images_path'][sum_df['random_split']==1], sum_df['Labels_path'][sum_df['random_split']==1], 512, 512, 4, 25)\n"
      ],
      "metadata": {
        "id": "yMEt7PPpNPlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_images, batch_labels = training_data_generator.__getitem__(0)"
      ],
      "metadata": {
        "id": "2RhN0onYhUno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0ivLGGtIMsz",
        "outputId": "7f0d11c3-4e4c-400d-e0f9-49f2a39c97d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 512, 512, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_labels.shape"
      ],
      "metadata": {
        "id": "KsMavBMDim_6",
        "outputId": "43747874-573a-46ff-d7a1-6e3218abc3b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 512, 512, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy','categorical_accuracy'])\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"landcover_segmentation.h5\", save_best_only=True)\n",
        "]\n",
        "\n",
        "model.fit(training_data_generator, validation_data=validation_data_generator, epochs=100, callbacks=callbacks,shuffle=True)\n",
        "# model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=16, epochs=10)\n",
        "\n"
      ],
      "metadata": {
        "id": "IG72KHv0Nmuk",
        "outputId": "3e975904-01ba-4ea7-913f-9a862419b362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "730/730 [==============================] - ETA: 0s - loss: 1.8993 - accuracy: 0.4109 - categorical_accuracy: 0.4109"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r730/730 [==============================] - 746s 975ms/step - loss: 1.8993 - accuracy: 0.4109 - categorical_accuracy: 0.4109 - val_loss: 1.7933 - val_accuracy: 0.4021 - val_categorical_accuracy: 0.4021\n",
            "Epoch 2/100\n",
            "730/730 [==============================] - 696s 953ms/step - loss: 1.6346 - accuracy: 0.4584 - categorical_accuracy: 0.4584 - val_loss: 1.6206 - val_accuracy: 0.4719 - val_categorical_accuracy: 0.4719\n",
            "Epoch 3/100\n",
            "730/730 [==============================] - 698s 955ms/step - loss: 1.5362 - accuracy: 0.4775 - categorical_accuracy: 0.4775 - val_loss: 1.5800 - val_accuracy: 0.4665 - val_categorical_accuracy: 0.4665\n",
            "Epoch 4/100\n",
            "730/730 [==============================] - 752s 1s/step - loss: 1.4662 - accuracy: 0.4963 - categorical_accuracy: 0.4963 - val_loss: 1.5872 - val_accuracy: 0.4483 - val_categorical_accuracy: 0.4483\n",
            "Epoch 5/100\n",
            "335/730 [============>.................] - ETA: 5:45 - loss: 1.4312 - accuracy: 0.5010 - categorical_accuracy: 0.5010"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-634d30130b02>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=16, epochs=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# history = model.fit(training_data_generator, validation_data=validation_data_generator, epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(validation_data_generator)\n",
        "print(\"Validation Loss:\", loss)\n",
        "print(\"Validation Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "egXgb8QoNum4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "807543dd-42c5-489b-d279-e14130d751be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82/82 [==============================] - 66s 804ms/step - loss: 1.6129 - accuracy: 0.4627 - categorical_accuracy: 0.4627\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-697d684c09fe>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    }
  ]
}